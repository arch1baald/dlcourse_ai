{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for FC0_w\n",
      "Gradient check passed!\n",
      "Checking gradient for FC0_b\n",
      "Gradient check passed!\n",
      "Checking gradient for FC2_w\n",
      "Gradient check passed!\n",
      "Checking gradient for FC2_b\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2], tol=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.3029004697376942\n",
      "loss with reg: 2.3973803449551423\n",
      "Checking gradient for FC0_w\n",
      "Gradient check passed!\n",
      "Checking gradient for FC0_b\n",
      "Gradient check passed!\n",
      "Checking gradient for FC2_w\n",
      "Gradient check passed!\n",
      "Checking gradient for FC2_b\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss_with_reg, loss)\n",
    "print('loss:', loss)\n",
    "print('loss with reg:', loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1023.647252, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 1, Loss: 1009.690136, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 2, Loss: 1004.566588, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 3, Loss: 1002.592345, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 4, Loss: 1001.428837, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 5, Loss: 999.503796, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 6, Loss: 994.617974, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 7, Loss: 984.942339, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 8, Loss: 971.917206, Train accuracy: 0.206222, val accuracy: 0.212000\n",
      "Epoch 9, Loss: 958.202508, Train accuracy: 0.234000, val accuracy: 0.237000\n",
      "Epoch 10, Loss: 943.907086, Train accuracy: 0.258778, val accuracy: 0.260000\n",
      "Epoch 11, Loss: 927.493135, Train accuracy: 0.272222, val accuracy: 0.271000\n",
      "Epoch 12, Loss: 906.772557, Train accuracy: 0.286667, val accuracy: 0.289000\n",
      "Epoch 13, Loss: 880.844922, Train accuracy: 0.306222, val accuracy: 0.314000\n",
      "Epoch 14, Loss: 850.759947, Train accuracy: 0.349111, val accuracy: 0.343000\n",
      "Epoch 15, Loss: 818.918998, Train accuracy: 0.383111, val accuracy: 0.382000\n",
      "Epoch 16, Loss: 788.202422, Train accuracy: 0.409111, val accuracy: 0.392000\n",
      "Epoch 17, Loss: 759.183523, Train accuracy: 0.437222, val accuracy: 0.428000\n",
      "Epoch 18, Loss: 732.864800, Train accuracy: 0.467333, val accuracy: 0.457000\n",
      "Epoch 19, Loss: 707.829049, Train accuracy: 0.494556, val accuracy: 0.488000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output=10, hidden_layer_size=100, reg=1e-6)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc9ad22a450>]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoVUlEQVR4nO3deXhU5dnH8e9NEnYEMQFkE2QVEQQC7gtWERRB1AqooIgiKrWrVevydtG2amvVqi8vKlRkFwRRUXGtWhWTIKtsEVkCQsIim5CQ5H7/mKHGOIEBkjnJ5Pe5rlyZc57nzPxyGO6cPOeZc8zdERGR+FUl6AAiIlK2VOhFROKcCr2ISJxToRcRiXMq9CIicS4x6ACRJCcne4sWLYKOISJSYWRkZGxx95RIbeWy0Ldo0YL09PSgY4iIVBhmtrakNg3diIjEuagKvZn1NrMVZpZpZndHaD/fzHaY2YLw1wPRbisiImXrkEM3ZpYAPA1cBGQBaWY2292/LNb1I3fve4TbiohIGYnmiL4HkOnuq909D5gC9I/y+Y9mWxERKQXRFPomwPoiy1nhdcWdYWYLzewNMzv5MLcVEZEyEs2sG4uwrviV0OYDJ7j7bjO7BJgFtIly29CLmI0ARgA0b948ilgiIhKNaI7os4BmRZabAhuLdnD3ne6+O/x4DpBkZsnRbFvkOca4e6q7p6akRJwKKiIiRyCaQp8GtDGzlmZWFRgEzC7awcwamZmFH/cIP+/WaLYVERHIWLuNZz9cTVlcOv6QQzfunm9mo4C3gARgrLsvNbOR4fbRwFXArWaWD+wFBnkobcRtS/2nEBGpwL7K2c3wF9I5tmZVrjmtObWqle5nWa083ngkNTXV9clYEakMsnft44pnPmHf/gJevvUsmh9X84iex8wy3D01Ulu5vASCiEhlsDs3n2Hj0ti2J48pI04/4iJ/KLoEgohIAPYXFHLbxPks37SLp6/tSqf6hbAls0xeS4VeRCTG3J27Zyzmw5U5/GXAKfRscxy8fDOM7QW5u0v99VToRURi7LG3VzJjfha/uLANV3dvBv9+BDLfgQvug2q1S/31VOhFRGJo4ry1/PO9TAZ1b8bPf9IGVs6Ffz8Mp14L3YaVyWuq0IuIxMg7X27m/llL6NkuhQcv74h9uzY0ZNOoI1z6d7BIFxM4eir0IiIx8MW67YyaPJ+OTery1DVdSSzMhalDAIerX4SkGmX22ppeKSJSxr7esofhL6TToE51xt7QnVpVE+CVn8OmRXDNNKjfskxfX0f0IiJlaMvuXG4Y9zkAL9zYg+Ta1WD+C7BgApz7W2h7cZlnUKEXESkj3+XlM/xfaWzeuY/nr0+lZXIt2JABc+6EVhfA+bG56Z4KvYhIGcgvKOT2ifNZvGEHTw3uSpfmx8KerTDteqjdCK58HqokxCSLxuhFREqZu3PfrCW8vyKHhwZ05MIODaGwAF6+CXZvhhvfgpr1Y5ZHhV5EpJQ9+W4mU9LWM6pna6497YTQyg/+Cl+9B5c9AU26xjSPhm5ERErRtLT1/OOdlVzZtSm/7tU2tHLFm/DhI9DlOuh6fcwzqdCLiJSS91dkc8/MxZzTJpm/XnkKZgbbvoaZI6BRJ7jkb2X2oaiDUaEXESkFi7N2cPvE+bRvVIf/va4bSQlVIO+78IeiDAaW7YeiDkZj9CIiRyl71z5uGp/GsTWrMu6G7tSulgju8PqvYfMSuPYlOLZFYPl0RC8ichTy8gu5bcJ8duzdz7NDU2lwTPVQQ8Y4WDgJzrsL2lwUaEYd0YuIHIU/vraU9LXbeXJwFzo0Pia0MisD3rgLWl8YKvQB0xG9iMgRmpq2jgmfreOWc0+kX+fGoZV7tsK0oVCnEVzxLFQJvszqiF5E5AjMX7ed+2ct5Zw2yfy2d/vQysICmHEj7MmB4XNj+qGog1GhFxE5TNk79zHyxQwa1q3GPwd3IaFKeMrk+w/B6g+g3z+h8alBRvyB4P+mEBGpQPLyC7l14nx27ctnzJBU6tWsGmpYPgc++jt0HRr6Kkd0RC8ichh+/+pSMtZu56lrunDS8eGTr5u/DN0p6vhToc+jgeaLREf0IiJRmvz5OibNW8fI81rRt9OBk69bYPJAqFobBk+GpOrBhowgqkJvZr3NbIWZZZpZiRdQNrPuZlZgZlcVWbfGzBab2QIzSy+N0CIisZaxdhsPvLKEc9umcOfF7UIr83Nh6nWwOxsGT4JjGgcbsgSHHLoxswTgaeAiIAtIM7PZ7v5lhH4PA29FeJqe7r6lFPKKiMTc5p37GDlhPsfXrcGTg04NnXx1h9d+Bes+DV1bvkm3oGOWKJoj+h5Apruvdvc8YArQP0K/nwEzgOxSzCciEqjc/AJGTshgT24+Y4Z2+/7k66dPfX87wFOuOviTBCyaQt8EWF9kOSu87r/MrAkwABgdYXsH5ppZhpmNKOlFzGyEmaWbWXpOTk4UsUREyt7vZy/li3Xf8refdqZ9o/DJ15Vvwdz7oUN/OP+eYANGIZpCH+maml5s+XHgLncviND3LHfvCvQBbjezcyO9iLuPcfdUd09NSUmJIpaISNmaOG8tkz9fz23nt+KSU44PrcxeBtOHw/Gd4PLR5eKTr4cSzfTKLKBZkeWmwMZifVKBKRa6znIycImZ5bv7LHffCODu2WY2k9BQ0IdHnVxEpAylr9nG72cv5fx2Kfy6V/jk656tMGkgVK0FgyZD1ZrBhoxSNL+K0oA2ZtbSzKoCg4DZRTu4e0t3b+HuLYDpwG3uPsvMaplZHQAzqwX0ApaU6k8gIlLKNu0InXxtUq8GTwwMf/I1Pw+mDQnd83XQJKjb5NBPVE4c8oje3fPNbBSh2TQJwFh3X2pmI8PtkcblD2gIzAwf6ScCk9z9zaOPLSJSNg6cfN2bl8+km0+jbs2k8LXlfwlr/xOaYdO0/M6wiSSqT8a6+xxgTrF1EQu8u99Q5PFqoPNR5BMRiRl354FZS1mw/ltGX9eVtg3rhBo+fRq+mADn3lnuZ9hEUv7PIoiIxMiEeeuYmr6eUT1b07tj+OTryrnw9v1wUj84/3fBBjxCKvQiIsDnX2/jD7OXckH7BvzyorahldnLYPqN0LAjDKgYM2wiqZipRURK0dqtexg5IYNm9Wvyj4HhT77+d4ZNTRg8JTTTpoLS1StFpFL79rs8hv0rjUJ3xt7Qnbo1kr6fYbNrEwybU6Fm2ESiQi8ilVZefiG3vJhB1ra9TLjpNFom1wrNsJnz69AMmyueg6apQcc8air0IlIpuTt3v7yIeV9v44lBp9KjZfi2f5/9L8wfD+f8Bjr9NNiQpURj9CJSKf3zvUxenr+BX13Ulv6nhodmVr0Nc++F9n2h573BBixFKvQiUunM+mIDj729kiu6NuFnF7QOrcxZEZ5hczJcMabCzrCJJH5+EhGRKHz+9TZ+O30Rp7Wsz1+uOAUzC91A5KUbILF6hZ9hE4nG6EWk0vh6yx5GvJhO02Nr8H9DulEtMSHU8O+HIftLuOYlqNs02JBlQEf0IlIpbN+Tx7Bxn1PFjHHDun9/A5ENGfDx43DqddC2V6AZy4qO6EUk7uXmFzDixXQ27tjHpJtO44TjwkMz+/fBrNugTiO4+KFgQ5YhFXoRiWvuzl3TF5G2ZjtPDu5Caov63zd+8BfIWQ7XzYAa9QLLWNY0dCMice3xd1Yxa8FG7ry4Hf06N/6+ISsdPnkSug6F1hcGFzAGVOhFJG7NyMjiiXdXcVW3ptx2fqvvG/bvhVm3Qp3G0Ct+h2wO0NCNiMSlz1Zv5e6XF3HGicfx5wHhaZQHvP8QbFkJQ2ZC9WOCCxkjOqIXkbjzVc5ubnkxg+b1azL6um5UTSxS6tbNg0+egm7DoNUFwYWMIRV6EYkrW3fnMmxcGolVjHE39AjdCvCAvO9CQzZ1m0GvPwUXMsY0dCMicWPf/gJGvJjB5p37mDzidJofV/OHHd57ELZ9BUNnQ7U6wYQMgAq9iMSFwkLnzumLyFi7naev6UrX5sf+sMPaT+GzZ6D7TXDiecGEDIiGbkQkLvxt7gpeXbiR3/Zux6Wdjv9hY94eeOU2qNccLvxDMAEDpCN6Eanwnv1wNc988BWDezTn1vNa/bjDu3+Ebavh+tegWu3YBwyYjuhFpEKblraeh+Ys49JTjufByzv+cBolwJqPYd5o6HELtDwnmJABU6EXkQrrzSXfcPfLizinTTKPDewcuql3Ubm74ZXb4diWcOH/BBOyHIiq0JtZbzNbYWaZZnb3Qfp1N7MCM7vqcLcVETkc/8ncwh2TF9C5Wb0fXnK4qHd+D9vXwuXPxN015g/HIQu9mSUATwN9gA7AYDPrUEK/h4G3DndbEZHD8cW67dw8Pp2WybUYd0N3alaNcLpx9b8h7Vk4/VY44czYhyxHojmi7wFkuvtqd88DpgD9I/T7GTADyD6CbUVEorJy8y6G/SuN5NrVeHF4j++vK19U7i6YPQrqt4IL7o99yHImmkLfBFhfZDkrvO6/zKwJMAAYfbjbFnmOEWaWbmbpOTk5UcQSkcpm/bbvGPL8PJISqjBh+Gk0OKZ65I5vPwDfrg8P2dSM3KcSiabQW4R1Xmz5ceAudy84gm1DK93HuHuqu6empKREEUtEKpPsXfsY8vw89uYV8OLwHj/+1OsBX70P6WPhjNuh+emxDVlORTOPPgtoVmS5KbCxWJ9UYEp4WlMycImZ5Ue5rYjIQe3Yu5/rx6axeWcuE246jfaNSrji5L6dMPtncFwbuOC+2IYsx6Ip9GlAGzNrCWwABgHXFO3g7i0PPDazfwGvufssM0s81LYiIgezN6+A4f9KIzN7F89f351uJxxbcue598HODXDjXEiqEbuQ5dwhC72755vZKEKzaRKAse6+1MxGhtuLj8sfctvSiS4i8S4vv5BbJ2aQsW47Tw3uyrltSxjWLSyEJdNh/gtw1s+hWffYBi3nzD3ikHmgUlNTPT09PegYIhKggkLnF1MX8OrCjfzlilMY3KP5jzvt3Q4LJkHa86GrUjbsCDe9C0klnKSNY2aW4e6pkdp0rRsRKXfcnf+ZvYRXF27krt7tf1zkN34Bac/B4hmQvxeanQbn3wMd+kFitWBCl2Mq9CJS7vx97komfLaOW847kVsP3Ot1/15YOjNU4DdkQFJN6DwQUofD8Z2CDVzOqdCLSLny3Eereer9TAZ1b8bdvduHrjqZPha+mBAaqkluC30egc6DoHrdoONWCCr0IlJuTEtfz4OvL+PSjik81CELm/gHyHwHLAFO6hu6aUiLc6D4FSrloFToRaRcmLt0E4/O+IhHGn7OT3Pewaauh9qNQmPvXYfCMY2DjlhhqdCLSODWb/uOhdMe5JNqk0nakR86au/1ILS/FBKSDv0EclAq9CISqIJC5/GJs3iYiew/oSdJff8CKe2CjhVXVOhFJFCjP1jF4Jx/UFC9LjUGPgc16wcdKe6o0ItIYBas/5aN7/0fqYkr8T7PqMiXERV6EQnEntx8fj/5fcYnTiG/2ZkknqrLYJUV3TNWRALxx1e/ZOiu56hdJZfEfo9rymQZUqEXkZh7c8k3rJv/JlckfEyVs36uk69lTEM3IhJTm3bs4/4Z85lZ4194nRbYub8JOlLcU6EXkZgpLHR+/dIChhTMoqlvgEtn6LrxMaChGxGJmec//poNXy3h9sRZcPIAaHNh0JEqBR3Ri0hMLN24g0ffWs6sepOoUlgdLv5L0JEqDRV6ESlze/MK+PmUBVxdfR4d9mZAn0fhmOODjlVpaOhGRMrcX95YRnb2Zh5ImgCNu0D34UFHqlR0RC8iZeq95ZsZ/+lapjd7g6pbtkHfGVAlIehYlYqO6EWkzOTsyuW30xfRP3kj3XJmQo9boPGpQceqdHRELyJlwt357fSFfLcvl4frjcOsEfT8XdCxKiUd0YtImXjxs7W8vyKHF07+gupblkKfh6H6MUHHqpRU6EWk1K3cvIuHXl/GFa2c1NX/C216wUn9go5VaanQi0ipys0v4I7JX1C7WiJ/rjER80K45FFdtCxAURV6M+ttZivMLNPM7o7Q3t/MFpnZAjNLN7Ozi7StMbPFB9pKM7yIlD9/e2sFyzftYuwZW6ieOQfO+y0c2yLoWJXaIU/GmlkC8DRwEZAFpJnZbHf/ski3d4HZ7u5m1gmYBrQv0t7T3beUYm4RKYc+XrWFZz/6mhu7N6Dz4rsgpT2cMSroWJVeNEf0PYBMd1/t7nnAFKB/0Q7uvtvdPbxYC3BEpFLZviePX01bQOsGtbmn1mzYsR76/gMSqwYdrdKLptA3AdYXWc4Kr/sBMxtgZsuB14EbizQ5MNfMMsxsREkvYmYjwsM+6Tk5OdGlF5Fy439mL2X7d3mM7lWdpM+fgS7XwQlnBh1LiK7QRzqD8qMjdnef6e7tgcuBPxVpOsvduwJ9gNvN7NxIL+LuY9w91d1TU1JSooglIuVFxtrtzF64kVvPbUnrefdDtWPgoj8dekOJiWgKfRbQrMhyU2BjSZ3d/UOglZklh5c3hr9nAzMJDQWJSJxwd/702pc0qFON2+t9CuvnQa8HdaPvciSaQp8GtDGzlmZWFRgEzC7awcxam4XmTplZV6AqsNXMaplZnfD6WkAvYElp/gAiEqzZCzeyYP233Hd+MtXe/wOccDboRt/lyiFn3bh7vpmNAt4CEoCx7r7UzEaG20cDVwJDzWw/sBcYGJ6B0xCYGf4dkAhMcvc3y+hnEZEY27e/gEfeXMHJx9fhsqy/Q94e6PuY5syXM1Fd68bd5wBziq0bXeTxw8DDEbZbDXQ+yowiUk49//HXbPh2L5PbfY4tnA0X/VE3+i6H9MlYETkiObtyeeb9TO5uvpzmCx+HzoPhzDuCjiURqNCLyBF57O2VtC7IZMS2R6BpD+j7uIZsyildplhEDtvyTTt5L20hb9d+nCo1U2DQREiqHnQsKYEKvYgcFnfnkVcX8Hy1x6jDHhg8E2o3CDqWHIQKvYgclg9WZHP5uj9zcsJq7IoJ0OiUoCPJIWiMXkSill9QyJqZf6BfwqcU9LwfTuobdCSJggq9iETtP6+OZVjuRDac0J/Ec38VdByJkgq9iERl15oMeiz4HSuT2tP4uv/TDJsKRIVeRA5t1yZ80iC2eW0Krp6IJdUIOpEcBhV6ETm4/XvJnTCIxNwdTG31CCe1aR10IjlMKvQiUjJ3eGUU1TZ/wV2Fo7imv06+VkQq9CJSso/+Bkum88j+q2l13iAa1dWHoioizaMXkci+nA3vPcgH1XoyI+lq3j/3xKATyRHSEb2I/Ng3C2HmLWw7thO37LieO3ufRM2qOi6sqFToReSHdm2GyYPx6vUYuufntGmSzBVdfnSbaKlAVOhF5Hv798GUa2Dvdqa1eZQlO2tw7yUdqFJFc+YrMhV6EQlxh9k/gw3p7OjzFH9MT6RXh4ac0eq4oJPJUVKhF5GQD/8Gi6dBz/v465o25BUUcs8lJwWdSkqBCr2IwKfPwPsPQqeBLGszgqlp6xl6RgtaJtcKOpmUAhV6kcoufSy8dQ+cdBne/2kenLOMY2okcccFbYJOJqVEhV6kMlswCV77JbS5GK4cy/urtvGfzK38/CdtqFszKeh0UkpU6EUqqyUz4JXb4cTz4erx7LdEHnp9GScm1+K6008IOp2UIhV6kcpo2Wsw42ZodjoMmgRJ1XnhkzV8lbOHey45iaQElYZ4oo+6iVQ2K+fCSzdAk65w7TQKE2vy+NsrefLdVZzfLoULT9L9X+NNVL+2zay3ma0ws0wzuztCe38zW2RmC8ws3czOjnZbEYmh1R/A1OugYQe4djq7qcEtEzJ48t1VXNm1KaOv64bphiJx55BH9GaWADwNXARkAWlmNtvdvyzS7V1gtru7mXUCpgHto9xWRGJh7ScweTAc1wqGzGLNniRuHv8fVm/ZwwN9OzDsrBYq8nEqmqGbHkCmu68GMLMpQH/gv8Xa3XcX6V8L8Gi3FZEYyMqAiVfDMU1g6Cv8O6uAn036mCpVjBdv7MGZrZODTihlKJqhmybA+iLLWeF1P2BmA8xsOfA6cOPhbBvefkR42Cc9JycnmuwiEo1vFsKEAVDrOHzoK4yZv4th4z6ncb0avDrqbBX5SiCaQh/pbzn/0Qr3me7eHrgc+NPhbBvefoy7p7p7akpKShSxROSQspfB+Muh2jHsu/YVfvlGNn+es5zeHRsx49YzaVa/ZtAJJQaiGbrJApoVWW4KbCyps7t/aGatzCz5cLcVkVK0JRNe6AcJVdk8YBo3Tc5iycYd/KZXW27v2Vrj8ZVINIU+DWhjZi2BDcAg4JqiHcysNfBV+GRsV6AqsBX49lDbikgZ2PY1vHAZeCGLL5rIsAkb2Le/kGeHpHJhh4ZBp5MYO2Shd/d8MxsFvAUkAGPdfamZjQy3jwauBIaa2X5gLzDQ3R2IuG0Z/SwiArAjC8b3g/y9vN71WX7x0haaHluTKSO60bpBnaDTSQAsVI/Ll9TUVE9PTw86hkjFs2sTjOuD78nhmeb/4NHFNTmvbQpPDu5C3Rq6dk08M7MMd0+N1KZPxorEiz1bYHx/fNcm7qvzIBMX12Tkea248+J2JOgOUZWaCr1IPPhmEbx0A4U7NjCqyr28l9OYJwZ1ov+puterqNCLVGzukP48/ubv2JtYl5ty72Zt7Y5MH9mNjk3qBp1OygkVepGKat8OmH0HfDmLL6qmctOOm2h7YgteuaYrybWrBZ1OyhEVepGKaMN8Cl4aBt+u59H8wUyvMoB7rurAlV2bUkXj8VKMCr1IReJO4Wej8bn3keP1GJV3PyefdhHvXtROd4SSEqnQi1QUe7ezY+pI6q55k7cLujKx0V38YcAZnNxYY/FycCr0IhXArsxPyZ82jNq52TyWcD0n9L2Tcd2a6jIGEhUVepFyrLCgkIUvPUTH5f9gsx/L9PajGX75AH34SQ6LCr1IOfVl5hr2TLuZ7nmfM6/amdQd9H/c3LJ50LGkAlKhFylntu/JY+rM6Vy26j5a2w4WdPwdPa64E6uiG3bLkVGhFyknCgudqWlryX7zEW4vnMzOaseTd81UTm3RPehoUsGp0IuUA5+t3so/X/2Mm7Y8zOCEhexs1Zf6Vz8D1TWjRo6eCr1IgL7K2c3o2R/S9usXGZP4PtWTCvDef+eY7sNBM2qklKjQiwRg6+5cpr36Oo2/fI4/V/mMhETwkweQcN5voMFJQceTOKNCLxJD+/Lyeef1KRy3YDS32mJyk2qQ3+Umks75GdRrdugnEDkCKvQiMeD5ecyf8zzHfDGavr6GbxOPY0v3e0g+byTUqBd0PIlzKvQiZWnfTta/8ww15j9Lt8ItrKnSnFWnP0ybnwyDRF1hUmJDhV6kLOzYwI4P/knVheNpVriHdOvI8h5/4syLB1ElQfPhJbZU6EVK06Yl5H30BAlLZ1DbC3mTM9jdZST9LulLjaoJQaeTSkqFXqQ05OdRMOt2EpZMI59qTMy/kOyONzHs0nNpUKd60OmkklOhFzla+/eyf/J1JK1+h6fy+7OsxVDu6Hsa7RrVCTqZCKBCL3J0cneRP3EgCes+4d78EZwz6NeM6tgo6FQiP6BCL3Kk9m6n4MUrsY1f8Kv82+l7zR1c2KFh0KlEfiSq0/9m1tvMVphZppndHaH9WjNbFP76xMw6F2lbY2aLzWyBmaWXZniRwOzOoXBcXwo3LuK2/b+k96BRKvJSbh3yiN7MEoCngYuALCDNzGa7+5dFun0NnOfu282sDzAGOK1Ie09331KKuUWCs3MjhS/0Y/+2ddyc9xt+OnAovTseH3QqkRJFc0TfA8h099XungdMAfoX7eDun7j79vDiZ0DT0o0pUk5sX4OP7U3utg0Myb2Ly6+6jss6Nw46lchBRVPomwDriyxnhdeVZDjwRpFlB+aaWYaZjTj8iCLlRM5KfGwf9uzcxsB993DlgJ9yRVcd00j5F83J2EjXSvWIHc16Eir0ZxdZfZa7bzSzBsDbZrbc3T+MsO0IYARA8+a6XZqUM5uW4OP7szO3gKv33st1/S9hYHe9T6ViiOaIPgsoelm9psDG4p3MrBPwHNDf3bceWO/uG8Pfs4GZhIaCfsTdx7h7qrunpqSkRP8TiJS1rAz8X5fybZ5x+Xf3MfDS3gw5/YSgU4lELZpCnwa0MbOWZlYVGATMLtrBzJoDLwND3H1lkfW1zKzOgcdAL2BJaYUXKXNrPsbH92NrQS0u23Mfg3r35MazWwadSuSwHHLoxt3zzWwU8BaQAIx196VmNjLcPhp4ADgOeMZCd8XJd/dUoCEwM7wuEZjk7m+WyU8iUtpWvYNPvZbshEZctvNOhlx0Grec1yroVCKHzdwjDrcHKjU11dPTNeVeArTsVfylYXxTrSWXbv8VQy7oyq96tQs6lUiJzCwjfID9I7peqkhxC6fi064nq0Y7em+/k6vPO5VfXtQ26FQiR0yFXqSo9HH4zFtYW6cLF2/9FVed1ZG7e7fHdKNuqcBU6EUO+PQZeO0XrD72TC7OHsWVp7fj/r4nqchLhaeLmokAfP4svHUPq5J/wiVZ13Nl95b8od/JKvISF3RELzJ/PMz5DV8n96RP1vVc1vUE/jzgFKpUUZGX+KBCL5Xbwqkw+w42Nzibi7Nu4OJOzXj0qs4q8hJXVOil8lo6C2aNZEej07lwwwhObdmQx67uTIKKvMQZjdFL5bTiDZgxnL0Nu3HxpttIqX8MY4Z0o1qibuAt8UeFXiqfzHdh2lD2N+jE5Tt+QX5iNV4Y1oN6NasGnUykTKjQS+Xy9Ucw5RoKk9tx/f67WLvbmTKiO83q1ww6mUiZ0Ri9VB7r5sGkgfixLbizxu/5dGMBTwzqwqnN6gWdTKRMqdBL5bBhPky8Cuo04h+N/8aM5bncf2kHLj65UdDJRMqcCr3Ev02L4cUBUKMe005+mifn7WTYWS10uWGpNFToJb5lL4fxl0PVWnx05ljuemcbvTo05L5LOwSdTCRmVOglfm39Csb3hyoJLOs1kZtf3UKnJnV5YlAXzZWXSkWFXuLT9rXwQj8o3M83/acyZNYWUupU47nru1OjqubKS+WiQi/xZ8cGGN8P8nax66fTGfLqTvLyCxl3Qw9S6lQLOp1IzKnQS3zZtTlU5PdsJe+aGdz8di7rtn7HmKGptG5QO+h0IoFQoZf4sWdraEx+5zf4tS9x16dJfLZ6G4/+tBOnn3hc0OlEAqNPxkrFVVgIOctgzcew5qPQ9/174dqX+MeK+sz8IpPf9GpL/1ObBJ1UJFAq9FJxFBZC9tJwYf8Y1v4H9m4PtdVrDm37QLcbmLa5MU++t4iBqc24vWfrYDOLlAMq9FJ+FRbA5iWw5j/fF/Z934ba6p0A7S6FFmdDi7NChR74aFUOv5uZxjltknlwQEfdIUqEeCv0+blBJ5Cj4Q45y78v6mv/A/t2hNqObQkn9YUW58AJZ0G9Zj/afPmmndw2YT6tG9TmmWu7kpSgU1AiEG+F/uEWsP+7oFNIaajfCjr0/76w1408zl5Y6Hzy1VYmf76OuV9uon6tqowb1p061ZNiHFik/IqvQn/+PVC4P+gUcjTqNg8NxRzT+KDdsnfu46WMLKamrWfdtu+oVzOJIae3YNhZLTi+bo0YhRWpGKIq9GbWG3gCSACec/e/Fmu/FrgrvLgbuNXdF0azbak6644ye2oJXkGh8+GqHCbPW8e7y7MpKHROP7E+v+7VlotPbkT1JH3iVSSSQxZ6M0sAngYuArKANDOb7e5fFun2NXCeu283sz7AGOC0KLcVOaiN3+5lWvp6XkrPYsO3ezmuVlVuOrslA7s348QUfQhK5FCiOaLvAWS6+2oAM5sC9Af+W6zd/ZMi/T8Dmka7rUgk+QWFvL8ih8mfr+ODFdkUOpzTJpl7Lz2JC09qSNVEnWgViVY0hb4JsL7IchZw2kH6DwfeONxtzWwEMAKgefPmUcSSeLR+23dMTVvPSxnr2bwzlwZ1qnHb+a0Z2L2ZbvcncoSiKfSRJiJ7xI5mPQkV+rMPd1t3H0NoyIfU1NSIfQ7lsn9+zL79BUeyqZQDBe58vWUPBpzfrgF/6t+MC9o3IFHTJEWOSjSFPgsoOmm5KbCxeCcz6wQ8B/Rx962Hs21paZVSi7yCwrJ6eomB/p2b8NPUpjSup5kzIqUlmkKfBrQxs5bABmAQcE3RDmbWHHgZGOLuKw9n29L0+KAuZfXUIiIV1iELvbvnm9ko4C1CUyTHuvtSMxsZbh8NPAAcBzwT/sh5vrunlrRtGf0sIiISgbkf0XB4mUpNTfX09PSgY4iIVBhmluHuqZHadJZLRCTOqdCLiMQ5FXoRkTinQi8iEudU6EVE4pwKvYhInCuX0yvNLAdYe4SbJwNbSjFOaVO+o6N8R0f5jk55zneCu6dEaiiXhf5omFl6SXNJywPlOzrKd3SU7+iU93wl0dCNiEicU6EXEYlz8VjoxwQd4BCU7+go39FRvqNT3vNFFHdj9CIi8kPxeEQvIiJFqNCLiMS5Clnozay3ma0ws0wzuztCu5nZk+H2RWbWNcb5mpnZ+2a2zMyWmtnPI/Q538x2mNmC8NcDMc64xswWh1/7R9eEDnIfmlm7IvtlgZntNLNfFOsT0/1nZmPNLNvMlhRZV9/M3jazVeHvx5aw7UHfr2WY71EzWx7+95tpZvVK2Pag74UyzPd7M9tQ5N/wkhK2DWr/TS2SbY2ZLShh2zLff0fN3SvUF6EbmHwFnAhUBRYCHYr1uYTQDcoNOB2YF+OMxwNdw4/rACsjZDwfeC3A/bgGSD5Ie6D7sNi/9yZCHwYJbP8B5wJdgSVF1j0C3B1+fDfwcAn5D/p+LcN8vYDE8OOHI+WL5r1Qhvl+D/wmin//QPZfsfa/Aw8Etf+O9qsiHtH3ADLdfbW75wFTgP7F+vQHxnvIZ0A9Mzs+VgHd/Rt3nx9+vAtYBjSJ1euXkkD3YRE/Ab5y9yP9pHSpcPcPgW3FVvcHXgg/fgG4PMKm0bxfyySfu8919/zw4meE7tkciBL2XzQC238HWOi2eVcDk0v7dWOlIhb6JsD6IstZ/LiIRtMnJsysBdAFmBeh+QwzW2hmb5jZybFNhgNzzSzDzEZEaC8v+3AQJf8HC3L/ATR0928g9MsdaBChT3nZjzcS+gstkkO9F8rSqPDQ0tgShr7Kw/47B9js7qtKaA9y/0WlIhZ6i7Cu+BzRaPqUOTOrDcwAfuHuO4s1zyc0HNEZ+CcwK8bxznL3rkAf4HYzO7dYe+D70MyqAv2AlyI0B73/olUe9uO9QD4wsYQuh3ovlJX/BVoBpwLfEBoeKS7w/QcM5uBH80Htv6hVxEKfBTQrstwU2HgEfcqUmSURKvIT3f3l4u3uvtPdd4cfzwGSzCw5VvncfWP4ezYwk9CfyEUFvg8J/ceZ7+6bizcEvf/CNh8Yzgp/z47QJ9D9aGbXA32Baz08oFxcFO+FMuHum929wN0LgWdLeN2g918icAUwtaQ+Qe2/w1ERC30a0MbMWoaP+AYBs4v1mQ0MDc8cOR3YceBP7FgIj+k9Dyxz98dK6NMo3A8z60Ho32JrjPLVMrM6Bx4TOmm3pFi3QPdhWIlHUkHuvyJmA9eHH18PvBKhTzTv1zJhZr2Bu4B+7v5dCX2ieS+UVb6i53wGlPC6ge2/sAuB5e6eFakxyP13WII+G3wkX4RmhKwkdDb+3vC6kcDI8GMDng63LwZSY5zvbEJ/Xi4CFoS/LimWcRSwlNAsgs+AM2OY78Tw6y4MZyiP+7AmocJdt8i6wPYfoV843wD7CR1lDgeOA94FVoW/1w/3bQzMOdj7NUb5MgmNbx94D44unq+k90KM8r0Yfm8tIlS8jy9P+y+8/l8H3nNF+sZ8/x3tly6BICIS5yri0I2IiBwGFXoRkTinQi8iEudU6EVE4pwKvYhInFOhFxGJcyr0IiJx7v8B/flucT8qwhkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1023.758117, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 1, Loss: 1010.009520, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 2, Loss: 1005.003458, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 3, Loss: 1003.140895, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 4, Loss: 1002.066056, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 5, Loss: 1000.524121, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 6, Loss: 996.857372, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 7, Loss: 988.905928, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 8, Loss: 977.702252, Train accuracy: 0.197111, val accuracy: 0.207000\n",
      "Epoch 9, Loss: 965.464759, Train accuracy: 0.221444, val accuracy: 0.228000\n",
      "Epoch 10, Loss: 952.710155, Train accuracy: 0.247111, val accuracy: 0.244000\n",
      "Epoch 11, Loss: 938.687490, Train accuracy: 0.261667, val accuracy: 0.268000\n",
      "Epoch 12, Loss: 921.735305, Train accuracy: 0.281556, val accuracy: 0.283000\n",
      "Epoch 13, Loss: 901.298387, Train accuracy: 0.302889, val accuracy: 0.306000\n",
      "Epoch 14, Loss: 878.399119, Train accuracy: 0.328556, val accuracy: 0.333000\n",
      "Epoch 15, Loss: 854.268997, Train accuracy: 0.357444, val accuracy: 0.361000\n",
      "Epoch 16, Loss: 829.016776, Train accuracy: 0.375222, val accuracy: 0.370000\n",
      "Epoch 17, Loss: 803.902024, Train accuracy: 0.398333, val accuracy: 0.395000\n",
      "Epoch 18, Loss: 780.510623, Train accuracy: 0.425222, val accuracy: 0.427000\n",
      "Epoch 19, Loss: 759.689657, Train accuracy: 0.452222, val accuracy: 0.448000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-3)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1002.057709, Train accuracy: 0.222333, val accuracy: 0.220000\n",
      "Epoch 1, Loss: 902.977935, Train accuracy: 0.368889, val accuracy: 0.378000\n",
      "Epoch 2, Loss: 733.038857, Train accuracy: 0.553889, val accuracy: 0.561000\n",
      "Epoch 3, Loss: 630.200936, Train accuracy: 0.622444, val accuracy: 0.609000\n",
      "Epoch 4, Loss: 583.061951, Train accuracy: 0.631333, val accuracy: 0.598000\n",
      "Epoch 5, Loss: 548.237917, Train accuracy: 0.699667, val accuracy: 0.679000\n",
      "Epoch 6, Loss: 526.782356, Train accuracy: 0.711778, val accuracy: 0.691000\n",
      "Epoch 7, Loss: 509.167051, Train accuracy: 0.730222, val accuracy: 0.695000\n",
      "Epoch 8, Loss: 499.740208, Train accuracy: 0.740556, val accuracy: 0.681000\n",
      "Epoch 9, Loss: 488.752688, Train accuracy: 0.693333, val accuracy: 0.658000\n",
      "Epoch 10, Loss: 483.313262, Train accuracy: 0.723444, val accuracy: 0.671000\n",
      "Epoch 11, Loss: 470.431527, Train accuracy: 0.766222, val accuracy: 0.731000\n",
      "Epoch 12, Loss: 465.566115, Train accuracy: 0.785778, val accuracy: 0.714000\n",
      "Epoch 13, Loss: 455.494237, Train accuracy: 0.771667, val accuracy: 0.707000\n",
      "Epoch 14, Loss: 453.843495, Train accuracy: 0.792000, val accuracy: 0.721000\n",
      "Epoch 15, Loss: 451.127243, Train accuracy: 0.796222, val accuracy: 0.731000\n",
      "Epoch 16, Loss: 443.149522, Train accuracy: 0.802000, val accuracy: 0.740000\n",
      "Epoch 17, Loss: 436.775864, Train accuracy: 0.796889, val accuracy: 0.712000\n",
      "Epoch 18, Loss: 440.651867, Train accuracy: 0.820556, val accuracy: 0.748000\n",
      "Epoch 19, Loss: 429.396272, Train accuracy: 0.788667, val accuracy: 0.709000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-3)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-2, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 6.922030, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Epoch 1, Loss: 6.885024, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Epoch 2, Loss: 6.853204, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Epoch 3, Loss: 6.822285, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Epoch 4, Loss: 6.789129, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Epoch 5, Loss: 6.772747, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Epoch 6, Loss: 6.684365, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Epoch 7, Loss: 6.587616, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Epoch 8, Loss: 6.416364, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 9, Loss: 6.195040, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 10, Loss: 5.798013, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 11, Loss: 5.435054, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 12, Loss: 5.289647, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 13, Loss: 5.008235, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 14, Loss: 4.860183, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 15, Loss: 4.818643, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 16, Loss: 5.032385, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 17, Loss: 4.774330, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 18, Loss: 4.555550, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Epoch 19, Loss: 4.291276, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 20, Loss: 4.271947, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Epoch 21, Loss: 4.123371, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 22, Loss: 3.907833, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Epoch 23, Loss: 3.841252, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 24, Loss: 3.646942, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Epoch 25, Loss: 3.506669, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Epoch 26, Loss: 3.344363, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Epoch 27, Loss: 3.085574, Train accuracy: 0.800000, val accuracy: 0.133333\n",
      "Epoch 28, Loss: 3.036072, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Epoch 29, Loss: 2.766790, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 30, Loss: 2.566173, Train accuracy: 0.800000, val accuracy: 0.133333\n",
      "Epoch 31, Loss: 2.375079, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 32, Loss: 2.259034, Train accuracy: 0.800000, val accuracy: 0.133333\n",
      "Epoch 33, Loss: 2.106012, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 34, Loss: 2.020708, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 35, Loss: 1.916953, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 36, Loss: 1.807483, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 37, Loss: 1.716246, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 38, Loss: 1.706693, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Epoch 39, Loss: 1.610133, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 40, Loss: 1.537527, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 41, Loss: 1.453742, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 42, Loss: 1.389161, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 43, Loss: 1.343316, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Epoch 44, Loss: 1.240561, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Epoch 45, Loss: 1.157143, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Epoch 46, Loss: 1.070259, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Epoch 47, Loss: 0.997128, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Epoch 48, Loss: 0.903532, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Epoch 49, Loss: 0.831254, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Epoch 50, Loss: 0.739226, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Epoch 51, Loss: 0.658211, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 52, Loss: 0.595709, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 53, Loss: 0.526094, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 54, Loss: 0.460447, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 55, Loss: 0.401404, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 56, Loss: 0.366506, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 57, Loss: 0.320327, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 58, Loss: 0.287333, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 59, Loss: 0.251113, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 60, Loss: 0.231176, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 61, Loss: 0.211105, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 62, Loss: 0.188488, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 63, Loss: 0.173763, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 64, Loss: 0.161198, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 65, Loss: 0.151548, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 66, Loss: 0.142464, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 67, Loss: 0.133541, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 68, Loss: 0.124731, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 69, Loss: 0.115662, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 70, Loss: 0.109640, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 71, Loss: 0.104249, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 72, Loss: 0.098257, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 73, Loss: 0.093690, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 74, Loss: 0.088892, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 75, Loss: 0.085389, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 76, Loss: 0.082143, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 77, Loss: 0.078153, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 78, Loss: 0.075559, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 79, Loss: 0.071937, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 80, Loss: 0.069908, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 81, Loss: 0.066892, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 82, Loss: 0.064391, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 83, Loss: 0.061903, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 84, Loss: 0.059692, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 85, Loss: 0.058415, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 86, Loss: 0.055900, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 87, Loss: 0.053978, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 88, Loss: 0.053034, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 89, Loss: 0.050886, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 90, Loss: 0.049642, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 91, Loss: 0.048474, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 92, Loss: 0.046997, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 93, Loss: 0.045442, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 94, Loss: 0.044401, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 95, Loss: 0.043441, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 96, Loss: 0.042153, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 97, Loss: 0.041036, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 98, Loss: 0.040185, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 99, Loss: 0.039151, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 100, Loss: 0.038166, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 101, Loss: 0.037222, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 102, Loss: 0.036458, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 103, Loss: 0.035782, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 104, Loss: 0.034900, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 105, Loss: 0.034080, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 106, Loss: 0.033469, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 107, Loss: 0.032770, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 108, Loss: 0.032021, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 109, Loss: 0.031428, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 110, Loss: 0.030725, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 111, Loss: 0.030068, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 112, Loss: 0.029618, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 113, Loss: 0.029154, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 114, Loss: 0.028521, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 115, Loss: 0.028148, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 116, Loss: 0.027541, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 117, Loss: 0.027011, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 118, Loss: 0.026659, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 119, Loss: 0.026092, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 120, Loss: 0.025688, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 121, Loss: 0.025293, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 122, Loss: 0.024813, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 123, Loss: 0.024440, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 124, Loss: 0.024002, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 125, Loss: 0.023640, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 126, Loss: 0.023298, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 127, Loss: 0.022942, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 128, Loss: 0.022536, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 129, Loss: 0.022303, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 130, Loss: 0.021941, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 131, Loss: 0.021611, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 132, Loss: 0.021302, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 133, Loss: 0.021002, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 134, Loss: 0.020712, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 135, Loss: 0.020402, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 136, Loss: 0.020145, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 137, Loss: 0.019898, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 138, Loss: 0.019567, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 139, Loss: 0.019314, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 140, Loss: 0.019068, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 141, Loss: 0.018868, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 142, Loss: 0.018597, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 143, Loss: 0.018342, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 144, Loss: 0.018152, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 145, Loss: 0.017931, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 146, Loss: 0.017636, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 147, Loss: 0.017433, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 148, Loss: 0.017265, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 149, Loss: 0.017068, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output=10, hidden_layer_size=100, reg=1e-6)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 6.916773, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Epoch 1, Loss: 6.794463, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 2, Loss: 6.626846, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Epoch 3, Loss: 6.004165, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 4, Loss: 5.393123, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Epoch 5, Loss: 5.184641, Train accuracy: 0.533333, val accuracy: 0.133333\n",
      "Epoch 6, Loss: 4.924417, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Epoch 7, Loss: 4.465237, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 8, Loss: 4.042994, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Epoch 9, Loss: 3.495173, Train accuracy: 0.800000, val accuracy: 0.133333\n",
      "Epoch 10, Loss: 3.330471, Train accuracy: 0.800000, val accuracy: 0.133333\n",
      "Epoch 11, Loss: 2.826936, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Epoch 12, Loss: 2.771648, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Epoch 13, Loss: 1.972838, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 14, Loss: 1.613137, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Epoch 15, Loss: 1.317800, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 16, Loss: 1.075459, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Epoch 17, Loss: 0.848562, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 18, Loss: 0.639540, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Epoch 19, Loss: 0.471012, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output=10, hidden_layer_size=3000, reg=1e-6)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=2e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1003.589125, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Epoch 1, Loss: 895.023949, Train accuracy: 0.412667, val accuracy: 0.417000\n",
      "Epoch 2, Loss: 742.132612, Train accuracy: 0.528000, val accuracy: 0.525000\n",
      "Epoch 3, Loss: 641.712801, Train accuracy: 0.618778, val accuracy: 0.610000\n",
      "Epoch 4, Loss: 574.758389, Train accuracy: 0.669222, val accuracy: 0.652000\n",
      "Epoch 5, Loss: 540.943640, Train accuracy: 0.693667, val accuracy: 0.663000\n",
      "Epoch 6, Loss: 522.125657, Train accuracy: 0.711556, val accuracy: 0.680000\n",
      "Epoch 7, Loss: 507.918903, Train accuracy: 0.715889, val accuracy: 0.689000\n",
      "Epoch 8, Loss: 495.375572, Train accuracy: 0.730222, val accuracy: 0.688000\n",
      "Epoch 9, Loss: 493.041882, Train accuracy: 0.736778, val accuracy: 0.693000\n",
      "Epoch 10, Loss: 482.871046, Train accuracy: 0.734778, val accuracy: 0.680000\n",
      "Epoch 11, Loss: 465.620891, Train accuracy: 0.768667, val accuracy: 0.708000\n",
      "Epoch 12, Loss: 467.265816, Train accuracy: 0.787778, val accuracy: 0.708000\n",
      "Epoch 13, Loss: 458.967488, Train accuracy: 0.789667, val accuracy: 0.714000\n",
      "Epoch 14, Loss: 455.790552, Train accuracy: 0.794889, val accuracy: 0.736000\n",
      "Epoch 15, Loss: 449.312008, Train accuracy: 0.793444, val accuracy: 0.716000\n",
      "Epoch 16, Loss: 438.786308, Train accuracy: 0.828444, val accuracy: 0.745000\n",
      "Epoch 17, Loss: 439.166427, Train accuracy: 0.809889, val accuracy: 0.727000\n",
      "Epoch 18, Loss: 432.354257, Train accuracy: 0.797556, val accuracy: 0.712000\n",
      "Epoch 19, Loss: 427.962494, Train accuracy: 0.811000, val accuracy: 0.723000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output=10, hidden_layer_size=100, reg=1e-3)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-2, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 431.032714, Train accuracy: 0.795111, val accuracy: 0.712000\n",
      "Epoch 1, Loss: 425.624675, Train accuracy: 0.837111, val accuracy: 0.746000\n",
      "Epoch 2, Loss: 417.579734, Train accuracy: 0.823222, val accuracy: 0.732000\n",
      "Epoch 3, Loss: 418.762394, Train accuracy: 0.843778, val accuracy: 0.747000\n",
      "Epoch 4, Loss: 408.402553, Train accuracy: 0.845000, val accuracy: 0.749000\n",
      "Epoch 5, Loss: 405.230266, Train accuracy: 0.805333, val accuracy: 0.718000\n",
      "Epoch 6, Loss: 405.697530, Train accuracy: 0.838556, val accuracy: 0.745000\n",
      "Epoch 7, Loss: 402.755472, Train accuracy: 0.861222, val accuracy: 0.773000\n",
      "Epoch 8, Loss: 401.729564, Train accuracy: 0.854556, val accuracy: 0.740000\n",
      "Epoch 9, Loss: 404.291424, Train accuracy: 0.836667, val accuracy: 0.747000\n",
      "Epoch 10, Loss: 399.781372, Train accuracy: 0.853889, val accuracy: 0.753000\n",
      "Epoch 11, Loss: 395.213920, Train accuracy: 0.862889, val accuracy: 0.758000\n",
      "Epoch 12, Loss: 396.041692, Train accuracy: 0.851222, val accuracy: 0.740000\n",
      "Epoch 13, Loss: 393.275232, Train accuracy: 0.851556, val accuracy: 0.748000\n",
      "Epoch 14, Loss: 386.541648, Train accuracy: 0.844889, val accuracy: 0.734000\n",
      "Epoch 15, Loss: 395.466584, Train accuracy: 0.864889, val accuracy: 0.757000\n",
      "Epoch 16, Loss: 388.489947, Train accuracy: 0.873778, val accuracy: 0.763000\n",
      "Epoch 17, Loss: 387.207821, Train accuracy: 0.871000, val accuracy: 0.740000\n",
      "Epoch 18, Loss: 390.988895, Train accuracy: 0.864000, val accuracy: 0.747000\n",
      "Epoch 19, Loss: 389.466221, Train accuracy: 0.852000, val accuracy: 0.744000\n"
     ]
    }
   ],
   "source": [
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006689717585696805"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 437.807245, Train accuracy: 0.828222, val accuracy: 0.728000\n",
      "Epoch 1, Loss: 433.344374, Train accuracy: 0.855889, val accuracy: 0.748000\n",
      "Epoch 2, Loss: 429.870111, Train accuracy: 0.834222, val accuracy: 0.743000\n",
      "Epoch 3, Loss: 423.082695, Train accuracy: 0.845556, val accuracy: 0.735000\n",
      "Epoch 4, Loss: 423.881662, Train accuracy: 0.829889, val accuracy: 0.729000\n",
      "Epoch 5, Loss: 421.887134, Train accuracy: 0.819111, val accuracy: 0.703000\n",
      "Epoch 6, Loss: 420.720048, Train accuracy: 0.845778, val accuracy: 0.731000\n",
      "Epoch 7, Loss: 420.946262, Train accuracy: 0.847667, val accuracy: 0.732000\n",
      "Epoch 8, Loss: 409.537437, Train accuracy: 0.848333, val accuracy: 0.735000\n",
      "Epoch 9, Loss: 423.322232, Train accuracy: 0.849222, val accuracy: 0.742000\n",
      "Epoch 10, Loss: 410.483562, Train accuracy: 0.848667, val accuracy: 0.743000\n",
      "Epoch 11, Loss: 410.507871, Train accuracy: 0.874889, val accuracy: 0.764000\n",
      "Epoch 12, Loss: 405.663441, Train accuracy: 0.879444, val accuracy: 0.758000\n",
      "Epoch 13, Loss: 407.076274, Train accuracy: 0.848000, val accuracy: 0.731000\n",
      "Epoch 14, Loss: 399.421091, Train accuracy: 0.868444, val accuracy: 0.753000\n",
      "Epoch 15, Loss: 408.340958, Train accuracy: 0.867778, val accuracy: 0.754000\n",
      "Epoch 16, Loss: 403.563899, Train accuracy: 0.880889, val accuracy: 0.772000\n",
      "Epoch 17, Loss: 408.377513, Train accuracy: 0.849333, val accuracy: 0.737000\n",
      "Epoch 18, Loss: 402.567590, Train accuracy: 0.866333, val accuracy: 0.762000\n",
      "Epoch 19, Loss: 400.397656, Train accuracy: 0.873556, val accuracy: 0.768000\n"
     ]
    }
   ],
   "source": [
    "trainer.learning_rate = 1e-2\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008179069375972308"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 395.706992, Train accuracy: 0.863222, val accuracy: 0.748000\n",
      "Epoch 1, Loss: 396.298364, Train accuracy: 0.859000, val accuracy: 0.727000\n",
      "Epoch 2, Loss: 395.203586, Train accuracy: 0.840111, val accuracy: 0.727000\n",
      "Epoch 3, Loss: 394.665493, Train accuracy: 0.818667, val accuracy: 0.714000\n",
      "Epoch 4, Loss: 395.290294, Train accuracy: 0.867222, val accuracy: 0.746000\n",
      "Epoch 5, Loss: 391.220166, Train accuracy: 0.885333, val accuracy: 0.767000\n",
      "Epoch 6, Loss: 386.589752, Train accuracy: 0.858000, val accuracy: 0.734000\n",
      "Epoch 7, Loss: 384.852209, Train accuracy: 0.893333, val accuracy: 0.770000\n",
      "Epoch 8, Loss: 384.611889, Train accuracy: 0.890556, val accuracy: 0.779000\n",
      "Epoch 9, Loss: 386.445803, Train accuracy: 0.894111, val accuracy: 0.762000\n",
      "Epoch 10, Loss: 380.923465, Train accuracy: 0.885667, val accuracy: 0.756000\n",
      "Epoch 11, Loss: 378.854580, Train accuracy: 0.874333, val accuracy: 0.766000\n",
      "Epoch 12, Loss: 386.292863, Train accuracy: 0.879000, val accuracy: 0.767000\n",
      "Epoch 13, Loss: 375.247174, Train accuracy: 0.894111, val accuracy: 0.768000\n",
      "Epoch 14, Loss: 376.079719, Train accuracy: 0.898444, val accuracy: 0.766000\n",
      "Epoch 15, Loss: 375.059031, Train accuracy: 0.885222, val accuracy: 0.769000\n",
      "Epoch 16, Loss: 372.586406, Train accuracy: 0.895667, val accuracy: 0.772000\n",
      "Epoch 17, Loss: 372.291732, Train accuracy: 0.898111, val accuracy: 0.765000\n",
      "Epoch 18, Loss: 376.902624, Train accuracy: 0.879444, val accuracy: 0.768000\n",
      "Epoch 19, Loss: 370.825903, Train accuracy: 0.870556, val accuracy: 0.745000\n"
     ]
    }
   ],
   "source": [
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 329.432646, Train accuracy: 0.935889, val accuracy: 0.787000\n",
      "Epoch 1, Loss: 315.598040, Train accuracy: 0.939222, val accuracy: 0.793000\n",
      "Epoch 2, Loss: 313.334157, Train accuracy: 0.938556, val accuracy: 0.800000\n",
      "Epoch 3, Loss: 312.167521, Train accuracy: 0.939778, val accuracy: 0.794000\n",
      "Epoch 4, Loss: 311.370503, Train accuracy: 0.943000, val accuracy: 0.798000\n",
      "Epoch 5, Loss: 310.652883, Train accuracy: 0.942333, val accuracy: 0.801000\n",
      "Epoch 6, Loss: 309.617698, Train accuracy: 0.939778, val accuracy: 0.793000\n",
      "Epoch 7, Loss: 309.139949, Train accuracy: 0.942889, val accuracy: 0.796000\n",
      "Epoch 8, Loss: 309.242936, Train accuracy: 0.942778, val accuracy: 0.802000\n",
      "Epoch 9, Loss: 308.300996, Train accuracy: 0.944667, val accuracy: 0.799000\n",
      "Epoch 10, Loss: 307.798310, Train accuracy: 0.940000, val accuracy: 0.795000\n",
      "Epoch 11, Loss: 307.588009, Train accuracy: 0.945556, val accuracy: 0.805000\n",
      "Epoch 12, Loss: 306.921439, Train accuracy: 0.945000, val accuracy: 0.801000\n",
      "Epoch 13, Loss: 306.834401, Train accuracy: 0.945000, val accuracy: 0.802000\n",
      "Epoch 14, Loss: 306.478333, Train accuracy: 0.947556, val accuracy: 0.797000\n",
      "Epoch 15, Loss: 306.178146, Train accuracy: 0.947111, val accuracy: 0.799000\n",
      "Epoch 16, Loss: 305.641046, Train accuracy: 0.946778, val accuracy: 0.801000\n",
      "Epoch 17, Loss: 305.399032, Train accuracy: 0.945222, val accuracy: 0.800000\n",
      "Epoch 18, Loss: 304.988540, Train accuracy: 0.944000, val accuracy: 0.796000\n",
      "Epoch 19, Loss: 304.914820, Train accuracy: 0.947000, val accuracy: 0.801000\n"
     ]
    }
   ],
   "source": [
    "trainer.learning_rate /= 10\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 304.427104, Train accuracy: 0.948000, val accuracy: 0.800000\n",
      "Epoch 1, Loss: 304.301584, Train accuracy: 0.947778, val accuracy: 0.798000\n",
      "Epoch 2, Loss: 303.973414, Train accuracy: 0.946778, val accuracy: 0.800000\n",
      "Epoch 3, Loss: 303.534781, Train accuracy: 0.945111, val accuracy: 0.797000\n",
      "Epoch 4, Loss: 303.581012, Train accuracy: 0.947000, val accuracy: 0.799000\n",
      "Epoch 5, Loss: 303.242791, Train accuracy: 0.948667, val accuracy: 0.801000\n",
      "Epoch 6, Loss: 302.925693, Train accuracy: 0.946333, val accuracy: 0.796000\n",
      "Epoch 7, Loss: 302.835860, Train accuracy: 0.949889, val accuracy: 0.805000\n",
      "Epoch 8, Loss: 302.505669, Train accuracy: 0.948111, val accuracy: 0.800000\n",
      "Epoch 9, Loss: 302.168044, Train accuracy: 0.949111, val accuracy: 0.801000\n",
      "Epoch 10, Loss: 302.167876, Train accuracy: 0.949222, val accuracy: 0.800000\n",
      "Epoch 11, Loss: 301.808240, Train accuracy: 0.948333, val accuracy: 0.804000\n",
      "Epoch 12, Loss: 301.750398, Train accuracy: 0.947889, val accuracy: 0.796000\n",
      "Epoch 13, Loss: 301.476338, Train accuracy: 0.950889, val accuracy: 0.802000\n",
      "Epoch 14, Loss: 301.165023, Train accuracy: 0.946889, val accuracy: 0.794000\n",
      "Epoch 15, Loss: 301.214467, Train accuracy: 0.951222, val accuracy: 0.801000\n",
      "Epoch 16, Loss: 300.646101, Train accuracy: 0.950556, val accuracy: 0.801000\n",
      "Epoch 17, Loss: 300.783378, Train accuracy: 0.948556, val accuracy: 0.797000\n",
      "Epoch 18, Loss: 300.520798, Train accuracy: 0.949222, val accuracy: 0.802000\n",
      "Epoch 19, Loss: 300.397484, Train accuracy: 0.949556, val accuracy: 0.799000\n"
     ]
    }
   ],
   "source": [
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00044752321376381087"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 303.431637, Train accuracy: 0.949556, val accuracy: 0.796000\n",
      "Epoch 1, Loss: 303.272138, Train accuracy: 0.946111, val accuracy: 0.798000\n",
      "Epoch 2, Loss: 302.405646, Train accuracy: 0.948556, val accuracy: 0.800000\n",
      "Epoch 3, Loss: 302.349742, Train accuracy: 0.948111, val accuracy: 0.792000\n",
      "Epoch 4, Loss: 302.128999, Train accuracy: 0.950111, val accuracy: 0.795000\n",
      "Epoch 5, Loss: 301.963428, Train accuracy: 0.950333, val accuracy: 0.799000\n",
      "Epoch 6, Loss: 301.412016, Train accuracy: 0.948222, val accuracy: 0.797000\n",
      "Epoch 7, Loss: 301.812633, Train accuracy: 0.949556, val accuracy: 0.795000\n",
      "Epoch 8, Loss: 301.163441, Train accuracy: 0.949444, val accuracy: 0.799000\n",
      "Epoch 9, Loss: 301.007980, Train accuracy: 0.950222, val accuracy: 0.798000\n",
      "Epoch 10, Loss: 300.688066, Train accuracy: 0.952889, val accuracy: 0.800000\n",
      "Epoch 11, Loss: 300.586106, Train accuracy: 0.951778, val accuracy: 0.801000\n",
      "Epoch 12, Loss: 300.510334, Train accuracy: 0.951222, val accuracy: 0.803000\n",
      "Epoch 13, Loss: 299.996283, Train accuracy: 0.951556, val accuracy: 0.799000\n",
      "Epoch 14, Loss: 300.089651, Train accuracy: 0.950000, val accuracy: 0.804000\n",
      "Epoch 15, Loss: 299.617106, Train accuracy: 0.952444, val accuracy: 0.804000\n",
      "Epoch 16, Loss: 299.649702, Train accuracy: 0.951556, val accuracy: 0.802000\n",
      "Epoch 17, Loss: 299.463655, Train accuracy: 0.952667, val accuracy: 0.796000\n",
      "Epoch 18, Loss: 299.220024, Train accuracy: 0.953667, val accuracy: 0.798000\n",
      "Epoch 19, Loss: 298.913078, Train accuracy: 0.951889, val accuracy: 0.795000\n"
     ]
    }
   ],
   "source": [
    "trainer.learning_rate *= 2\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 294.905345, Train accuracy: 0.954111, val accuracy: 0.801000\n",
      "Epoch 1, Loss: 294.187918, Train accuracy: 0.954889, val accuracy: 0.798000\n",
      "Epoch 2, Loss: 293.935956, Train accuracy: 0.954556, val accuracy: 0.801000\n",
      "Epoch 3, Loss: 293.920912, Train accuracy: 0.955444, val accuracy: 0.798000\n",
      "Epoch 4, Loss: 293.857191, Train accuracy: 0.955333, val accuracy: 0.800000\n",
      "Epoch 5, Loss: 293.818077, Train accuracy: 0.955667, val accuracy: 0.800000\n",
      "Epoch 6, Loss: 293.817567, Train accuracy: 0.955333, val accuracy: 0.800000\n",
      "Epoch 7, Loss: 293.743369, Train accuracy: 0.955222, val accuracy: 0.797000\n",
      "Epoch 8, Loss: 293.724874, Train accuracy: 0.955778, val accuracy: 0.799000\n",
      "Epoch 9, Loss: 293.711878, Train accuracy: 0.955222, val accuracy: 0.799000\n",
      "Epoch 10, Loss: 293.654544, Train accuracy: 0.955333, val accuracy: 0.799000\n",
      "Epoch 11, Loss: 293.641173, Train accuracy: 0.955556, val accuracy: 0.797000\n",
      "Epoch 12, Loss: 293.670496, Train accuracy: 0.955444, val accuracy: 0.799000\n",
      "Epoch 13, Loss: 293.603275, Train accuracy: 0.955000, val accuracy: 0.798000\n",
      "Epoch 14, Loss: 293.545846, Train accuracy: 0.954889, val accuracy: 0.799000\n",
      "Epoch 15, Loss: 293.551688, Train accuracy: 0.955222, val accuracy: 0.801000\n",
      "Epoch 16, Loss: 293.581788, Train accuracy: 0.955222, val accuracy: 0.800000\n",
      "Epoch 17, Loss: 293.537986, Train accuracy: 0.955444, val accuracy: 0.801000\n",
      "Epoch 18, Loss: 293.477629, Train accuracy: 0.956556, val accuracy: 0.800000\n",
      "Epoch 19, Loss: 293.498175, Train accuracy: 0.955889, val accuracy: 0.797000\n"
     ]
    }
   ],
   "source": [
    "trainer.learning_rate /= 10\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 293.035429, Train accuracy: 0.956111, val accuracy: 0.797000\n",
      "Epoch 1, Loss: 293.023264, Train accuracy: 0.956000, val accuracy: 0.797000\n",
      "Epoch 2, Loss: 293.014285, Train accuracy: 0.956000, val accuracy: 0.797000\n",
      "Epoch 3, Loss: 293.007220, Train accuracy: 0.955889, val accuracy: 0.798000\n",
      "Epoch 4, Loss: 293.003991, Train accuracy: 0.956000, val accuracy: 0.799000\n",
      "Epoch 5, Loss: 293.001057, Train accuracy: 0.956000, val accuracy: 0.800000\n",
      "Epoch 6, Loss: 292.996881, Train accuracy: 0.955889, val accuracy: 0.800000\n",
      "Epoch 7, Loss: 292.996955, Train accuracy: 0.955889, val accuracy: 0.800000\n",
      "Epoch 8, Loss: 292.993453, Train accuracy: 0.955889, val accuracy: 0.800000\n",
      "Epoch 9, Loss: 292.989740, Train accuracy: 0.955778, val accuracy: 0.800000\n",
      "Epoch 10, Loss: 292.986937, Train accuracy: 0.955778, val accuracy: 0.800000\n",
      "Epoch 11, Loss: 292.984249, Train accuracy: 0.955667, val accuracy: 0.800000\n",
      "Epoch 12, Loss: 292.983740, Train accuracy: 0.955667, val accuracy: 0.800000\n",
      "Epoch 13, Loss: 292.981648, Train accuracy: 0.955556, val accuracy: 0.800000\n",
      "Epoch 14, Loss: 292.979216, Train accuracy: 0.955667, val accuracy: 0.800000\n",
      "Epoch 15, Loss: 292.976945, Train accuracy: 0.955667, val accuracy: 0.800000\n",
      "Epoch 16, Loss: 292.976584, Train accuracy: 0.955667, val accuracy: 0.800000\n",
      "Epoch 17, Loss: 292.971488, Train accuracy: 0.955667, val accuracy: 0.800000\n",
      "Epoch 18, Loss: 292.969585, Train accuracy: 0.955667, val accuracy: 0.800000\n",
      "Epoch 19, Loss: 292.969332, Train accuracy: 0.955667, val accuracy: 0.800000\n"
     ]
    }
   ],
   "source": [
    "trainer.learning_rate /= 10\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.779"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metrics import multiclass_accuracy\n",
    "\n",
    "multiclass_accuracy(trainer.model.predict(test_X), test_y)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m75"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
